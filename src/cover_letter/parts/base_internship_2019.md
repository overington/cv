### 2019 SEPNet Internship: Machine Learning and Computer Vision.
<!--
- Built object detection model for earth observation data, to detect and differentiate between biodiversity types (Python, TensorFlow and Keras).
- Researched and implemented methods of transfer learning in NNs for a project constrained by limited labelled dataset; improving training time.
- Created internal reference documentation for CVAT (Computer Vision Annotation Tool).
- Collaborated on a poster researching computer vision methods using machine learning, neural networks and transfer learning.
 -->

 I took part in the South-Eastern Physics Network (SEPNet) internship programme, joining the Earth Observation team at Deimos Space UK.  I lead an investigative project to produce NN object detection models that could differentiate between various types of vegetation and biodiversity; highlighting regions of high detection density of a particular biodiversity class within an image. The model would be used in a project for their farming industry partners with the aim to reduce chemical usage extracting optimal areas to target the resources. On completion of the project, I produced a report and research poster and presented my findings and results at the SEPNet presentation day.

 I used python and libraries Keras, TensorFlow, PIL, Pandas, and NumPy to batch process the labelled images, and then trained the model on them using a dedicated high power GPU server. The trained model could then be used to classify a stream of images on the fly, or be saved for later use further down in the partner pipeline.

 I research and implemented the process of transfer learning in neural networks as within the project remit, it was specified that there would be limited availability of labelled source imagery. This increased the feature extraction accuracy and decreased the training time (when compared to the same dataset without using transfer learning).

<!--
South-Eastern Physics Network (SEPNet) internship programme.
Working with the Earth observation team on the KORE project
extracts information from satellite / UAV imagery about cropland

My project (I created):
			- NN / Object detection pipeline
      - Training images were outlined using CVAT
			   - Then the outlines and the training image were split into tiles
				 - where the pipeline that I created would split the training input image into tiles;
				 - Then each tile was input,
			- Detect a species of biodiversity within a given image: creating a heatmap
			ยง Python, numpy, PIL (python image lib), TensorFlow, Keras.
			ยง model was trained on images from a variable number of labels; which would retrieved from the customer, and then sent through the pipeline to be categorised.
			ยง Not quite pixel level.

-->
